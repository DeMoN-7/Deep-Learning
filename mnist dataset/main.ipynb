{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing datest from tensorflow lib\n",
    "mnis=tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "# splitting dataset\n",
    "(x_train,y_train),(x_test,y_test)=mnis.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# showing data \n",
    "plt.imshow(x_test[0],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing data or we can say scaling the data \n",
    "x_train=tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test=tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "model=tf.keras.models.Sequential()\n",
    "# flattening the data or converting image to from 2d image to 1d image\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# dense layer is a fully connected layer where each neuron is connected to every neuron in the previous layer\n",
    "# 128 means it has 128 neurons which means it has 128 weights for each input features\n",
    "# activation function which is used is relu \n",
    "#  f(x)=max(0,x)\n",
    "# basically the layer learns 128 features from the data by combining the inputs and applying relu \n",
    "# this part is hidden layer \n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "# this layer process the features learned by previous layer\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "\n",
    "# softmax is applied to the output layers \n",
    "# it converts output to probab of 10(cos dataset contains of only 10 classes i.e: 0-9)classes.\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "# loss function calculate how the model is performing \n",
    "# or \n",
    "# we can say how much prediction is correct in comparison to labels\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9837 - loss: 0.0530\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9878 - loss: 0.0378\n",
      "Epoch 3/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9914 - loss: 0.0268\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history=model.fit(x_train,y_train,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.9711 - loss: 0.1034\n",
      "acc 0.9746999740600586\n",
      "val loss 0.09119431674480438\n"
     ]
    }
   ],
   "source": [
    "# evaluating the model or calculating the accuracy or loss\n",
    "val_loss,val_acc=model.evaluate(x_test,y_test)\n",
    "print(\"acc\",val_acc)\n",
    "print(\"val loss\",val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# saving the model\n",
    "model.save(\"Digit_Reco.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
